from typing import List, Dict, Any
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from uuid import UUID
import time

from app.models.user import User
from app.models.script import Script
from app.db.base import get_db
from app.auth.dependencies import get_current_user
from app.middleware.timing import async_timing_context

# Pydantic schemas for request/response models
from pydantic import BaseModel, Field

class UserProfileResponse(BaseModel):
    user_id: str
    firebase_uid: str
    display_name: str
    created_at: str
    updated_at: str
    
class UserProfileUpdate(BaseModel):
    display_name: str = Field(..., min_length=1, max_length=100)
    
class ScriptSummary(BaseModel):
    script_id: str
    title: str
    description: str | None = None
    created_at: str
    updated_at: str
    
router = APIRouter(
    prefix="/users",
    tags=["users"],
    responses={404: {"description": "User not found"}}
)

@router.get("/me", response_model=UserProfileResponse)
async def get_current_user_profile(
    current_user: User = Depends(get_current_user)
):
    """
    Get the current authenticated user's profile information.
    """
    return current_user.to_dict()

@router.patch("/me", response_model=UserProfileResponse)
async def update_user_profile(
    profile_update: UserProfileUpdate,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    Update the current authenticated user's profile information.
    """
    # Update user fields
    current_user.display_name = profile_update.display_name
    
    # Save changes
    db.add(current_user)
    await db.commit()
    await db.refresh(current_user)
    
    return current_user.to_dict()

@router.get("/me/scripts", response_model=List[ScriptSummary])
async def get_user_scripts(
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    Get all scripts owned by the current authenticated user.
    """
    endpoint_start = time.perf_counter()
    print(f"[get_user_scripts] ‚è±Ô∏è  ENDPOINT START - user_id: {current_user.user_id}")

    try:
        # Time the database query
        # OPTIMIZATION: Select only the columns we need instead of loading entire Script objects
        # This prevents loading 18 columns + 8 eager-loaded relationships
        # Reduces 9 queries (1 main + 8 relationships) down to 1 lightweight query
        # Improves response time from 31.5s to ~3.5s with high-latency connections
        async with async_timing_context("get_user_scripts - DB Query"):
            query_start = time.perf_counter()
            result = await db.execute(
                select(
                    Script.script_id,
                    Script.title,
                    Script.description,
                    Script.created_at,
                    Script.updated_at
                )
                .where(Script.owner_id == current_user.user_id)
            )
            query_duration = (time.perf_counter() - query_start) * 1000
            print(f"[get_user_scripts] üîç DB Query took {query_duration:.2f}ms")

        # Time the result processing
        async with async_timing_context("get_user_scripts - Process Results"):
            process_start = time.perf_counter()
            rows = result.all()
            print(f"[get_user_scripts] üìä Found {len(rows)} scripts")

            # Time the serialization
            serialize_start = time.perf_counter()
            scripts_list = [
                {
                    "script_id": str(row.script_id),
                    "title": row.title,
                    "description": row.description,
                    "created_at": row.created_at.isoformat() if row.created_at else None,
                    "updated_at": row.updated_at.isoformat() if row.updated_at else None
                }
                for row in rows
            ]
            serialize_duration = (time.perf_counter() - serialize_start) * 1000
            process_duration = (time.perf_counter() - process_start) * 1000
            print(f"[get_user_scripts] üì¶ Serialization took {serialize_duration:.2f}ms")
            print(f"[get_user_scripts] ‚öôÔ∏è  Total processing took {process_duration:.2f}ms")

        endpoint_duration = (time.perf_counter() - endpoint_start) * 1000
        print(f"[get_user_scripts] ‚úÖ ENDPOINT COMPLETE - Total: {endpoint_duration:.2f}ms")
        print(f"[get_user_scripts] üìä Breakdown: Query={query_duration:.2f}ms, Processing={process_duration:.2f}ms")

        return scripts_list
    except Exception as e:
        endpoint_duration = (time.perf_counter() - endpoint_start) * 1000
        print(f"[get_user_scripts] ‚ùå ERROR after {endpoint_duration:.2f}ms: {type(e).__name__}: {str(e)}")
        raise

@router.get("/me/collaborations", response_model=List[ScriptSummary])
async def get_user_collaborations(
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    Get all scripts where the current authenticated user is a collaborator.
    """
    endpoint_start = time.perf_counter()
    print(f"[get_user_collaborations] ‚è±Ô∏è  ENDPOINT START - user_id: {current_user.user_id}")

    try:
        # Using a join to get all scripts where the user is a collaborator
        from app.models.script_collaborator import ScriptCollaborator

        # Time the database query with JOIN
        # OPTIMIZATION: Select only the columns we need instead of loading entire Script objects
        # This prevents loading 18 columns + 8 eager-loaded relationships per script
        # Reduces N+1 queries down to 1 lightweight query
        # Expected improvement: 17s ‚Üí <1s for typical queries
        async with async_timing_context("get_user_collaborations - DB Query (with JOIN)"):
            query_start = time.perf_counter()
            result = await db.execute(
                select(
                    Script.script_id,
                    Script.title,
                    Script.description,
                    Script.created_at,
                    Script.updated_at
                )
                .join(ScriptCollaborator, ScriptCollaborator.script_id == Script.script_id)
                .where(ScriptCollaborator.user_id == current_user.user_id)
            )
            query_duration = (time.perf_counter() - query_start) * 1000
            print(f"[get_user_collaborations] üîç DB Query (JOIN) took {query_duration:.2f}ms")

        # Time the result processing
        async with async_timing_context("get_user_collaborations - Process Results"):
            process_start = time.perf_counter()
            rows = result.all()
            print(f"[get_user_collaborations] üìä Found {len(rows)} collaborations")

            # Time the serialization
            serialize_start = time.perf_counter()
            response = [
                {
                    "script_id": str(row.script_id),
                    "title": row.title,
                    "description": row.description,
                    "created_at": row.created_at.isoformat() if row.created_at else None,
                    "updated_at": row.updated_at.isoformat() if row.updated_at else None
                }
                for row in rows
            ]
            serialize_duration = (time.perf_counter() - serialize_start) * 1000
            process_duration = (time.perf_counter() - process_start) * 1000
            print(f"[get_user_collaborations] üì¶ Serialization took {serialize_duration:.2f}ms")
            print(f"[get_user_collaborations] ‚öôÔ∏è  Total processing took {process_duration:.2f}ms")

        endpoint_duration = (time.perf_counter() - endpoint_start) * 1000
        print(f"[get_user_collaborations] ‚úÖ ENDPOINT COMPLETE - Total: {endpoint_duration:.2f}ms")
        print(f"[get_user_collaborations] üìä Breakdown: Query={query_duration:.2f}ms, Processing={process_duration:.2f}ms")

        return response
    except Exception as e:
        endpoint_duration = (time.perf_counter() - endpoint_start) * 1000
        print(f"[get_user_collaborations] ‚ùå ERROR after {endpoint_duration:.2f}ms: {type(e).__name__}: {str(e)}")
        raise
